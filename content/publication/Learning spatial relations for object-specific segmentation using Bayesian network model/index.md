---
title: "Learning spatial relations for object-specific segmentation using Bayesian network model"
authors:
    - Iker Gondra
    - admin

date: "2012-09-14"
# doi: "10.1007/s11760-012-0376-3"

# Schedule page publish date (NOT publication's date).
publishDate: "2012-09-14"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["2"]

# Publication name and optional abbreviated publication name.
publication: Signal, Image and Video Processing (Springer)
publication_short: "*Signal, Image and Video Processing, Springer Nature*"

abstract: In computer vision tasks such as, for example, object recognition, semantically accurate segmentation of a particular object of interest (OOI) is a critical step. Due to the OOI consisting of visually different fragments, traditional segmentation algorithms that are based on the identification of homogeneous regions usually do not perform well. In order to narrow this gap between low-level visual features and high-level semantics, some recent methods employ machine learning to generate more accurate models of the OOI. The main contribution of this paper is the inclusion of spatial relationships among the OOI fragments into the model. For this purpose, we employ Bayesian networks as a probabilistic approach for learning the spatial relationships which, in turn, becomes evidence that is used for the process of segmenting future instances of the OOI. The algorithm presented in this paper also uses multiple instance learning to obtain prototypical descriptions of each fragment of the OOI based on low-level visual features. The experimental results on both artificial and real image datasets indicate that the addition of spatial relationships improves segmentation performance.

# Summary. An optional shortened abstract.
summary: In computer vision tasks such as, for example, object recognition, semantically accurate segmentation of a particular object of interest (OOI) is a critical step. Due to the OOI consisting of visually different fragments, traditional segmentation algorithms that are based on the identification of homogeneous regions usually do not perform well. In order to narrow this gap between low-level visual features and high-level semantics, some recent methods employ machine learning to generate more accurate models of the OOI. The main contribution of this paper is the inclusion of spatial relationships among the OOI fragments into the model. For this purpose, we employ Bayesian networks as a probabilistic approach for learning the spatial relationships which, in turn, becomes evidence that is used for the process of segmenting future instances of the OOI. The algorithm presented in this paper also uses multiple instance learning to obtain prototypical descriptions of each fragment of the OOI based on low-level visual features. The experimental results on both artificial and real image datasets indicate that the addition of spatial relationships improves segmentation performance.

tags:
    - Bayesian Network
    - Image Processing
    - Probabilistic

featured: true

# links:
#     - name: Custom Link
#       url: http://example.org
url_source: "https://link.springer.com/article/10.1007/s11760-012-0376-3"
# url_code: "#"
# url_dataset: "#"
# url_pdf: "#"
# url_poster: "#"
# url_project: "#"
# url_slides: "#"
# url_video: "#"

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# # image:
#     caption: "Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)"
#     focal_point: ""
#     preview_only: false
# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
# projects:
#     - internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
# slides: example
---

<!-- {{% callout note %}}
Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the _Slides_ button to check out the example.
{{% /callout %}}

Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -->
